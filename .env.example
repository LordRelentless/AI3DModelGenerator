OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Model Configuration
SHAP_E_MODEL=openai/shap-e
TRIPOSR_MODEL=stabilityai/triposr
DEVICE=auto

# Server Configuration
SERVER_HOST=0.0.0.0  # Server bind address (0.0.0.0 listens on all interfaces)
API_HOST=127.0.0.1   # Client connection address (127.0.0.1 for local, or server IP for remote)
API_PORT=5000
DEBUG=False

# LLM Configuration (Local LLM is prioritized by default)
DEFAULT_LLM=auto  # auto, local, openai, anthropic, openrouter
LOCAL_LLM_ENABLED=True
LOCAL_LLM_PATH=./models/llm
LOCAL_LLM_TYPE=transformers  # Options: transformers, glm4
# For GLM 4.7: LOCAL_LLM_PATH=THUDM/glm-4-9b-chat

# Networked LLM Configuration (e.g., LM Studio, oobabooga)
NETWORKED_LLM_URL=
NETWORKED_LLM_API_KEY=

# Model Auto-Download Configuration
AUTO_DOWNLOAD_MODELS=false  # Automatically download models on startup
AUTO_DOWNLOAD_3D_MODELS=true  # Download Shap-E, TripoSR
AUTO_DOWNLOAD_LLM_MODELS=false  # Download LLM models

# 3D Generation Configuration
DEFAULT_INFERENCE_STEPS=50
DEFAULT_GUIDANCE_SCALE=7.5
DEFAULT_FRAME_SIZE=256
MESH_RESOLUTION=256

# Output Configuration
OUTPUT_DIR=./output
MODELS_DIR=./models
LOGS_DIR=./logs

# GUI Configuration
WINDOW_WIDTH=1400
WINDOW_HEIGHT=900

# Web Server Configuration
WEB_PORT=8000
